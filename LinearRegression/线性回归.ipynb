{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归\n",
    "主要内容包括：\n",
    "\n",
    "1. 线性回归的基本要素\n",
    "2. 线性回归模型从零开始的实现\n",
    "3. 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矢量计算\n",
    "在模型训练或预测时，我们常常会同时处理多个数据样本并用到矢量计算。在介绍线性回归的矢量计算表达式之前，让我们先考虑对两个向量相加的两种方法。\n",
    "\n",
    "\n",
    "1. 向量相加的一种方法是，将这两个向量按元素逐一做标量加法。\n",
    "2. 向量相加的另一种方法是，将这两个向量直接做矢量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "n=1000\n",
    "a=torch.ones(n)\n",
    "b=torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a timer class to record time(object):\n",
    "\n",
    "class Timer(object):\n",
    "    def __init__(self):\n",
    "        self.time=[]\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self.start_time= time.time()\n",
    "    \n",
    "    def stop(self):\n",
    "        spend_times=time.time()-self.start_time\n",
    "        self.time.append(spend_times)\n",
    "        return self.time[-1]\n",
    "    def avg(self):\n",
    "        return sum(self.times)/len(self.times)\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以来测试了。首先将两个向量使用for循环按元素逐一做标量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spend 0.025933265686035156 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer=Timer()\n",
    "c=torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i]=a[i]+b[i]\n",
    "'spend {} sec'.format(timer.stop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外是使用torch来将两个向量直接做矢量加法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spend 0.0 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d=a.add(b)\n",
    "'spend {} sec'.format(timer.stop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果很明显,后者比前者运算速度更快。因此，我们应该尽可能采用矢量计算，以提升计算效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型从零开始的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据集\n",
    "使用线性模型来生成数据集，生成一个1000个样本的数据集，下面是用来生成数据的线性关系：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs=2\n",
    "num_examples=1000\n",
    "true_w=[2,-3.4]\n",
    "true_b=4.2\n",
    "features=torch.randn(num_examples,num_inputs,dtype=torch.float32)\n",
    "labels=true_w[0]*features[:,0]+true_w[1]*features[:,1]+true_b\n",
    "labels+=torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用图像来展示生成的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(),2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0,j), labels.index_select(0,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9583, -0.8601],\n",
      "        [ 0.5868, -0.3833],\n",
      "        [ 0.6927,  0.3609],\n",
      "        [-0.2241,  0.2865],\n",
      "        [ 1.7433,  2.0418],\n",
      "        [ 0.1141, -0.9127],\n",
      "        [-1.4794,  1.1205],\n",
      "        [-1.4080, -0.6492],\n",
      "        [ 0.9555, -0.4203],\n",
      "        [-0.6599,  0.1867]]) \n",
      " tensor([11.0505,  6.6777,  4.3579,  2.7877,  0.7577,  7.5227, -2.5674,  3.6003,\n",
      "         7.5384,  2.2312])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0004],\n",
      "        [-0.0075]])\n",
      "tensor([0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\n",
    "print(w)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "print(b)\n",
    "\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "定义用来训练参数的训练模型：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数\n",
    "我们使用的是均方误差损失函数：\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): \n",
    "    return (y_hat - y.view(y_hat.size())) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化函数\n",
    "在这里优化函数使用的是小批量随机梯度下降：\n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "当数据集、模型、损失函数和优化函数定义完了之后就可来准备进行模型的训练了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.048526\n",
      "epoch 2, loss 0.000196\n",
      "epoch 3, loss 0.000045\n",
      "epoch 4, loss 0.000044\n",
      "epoch 5, loss 0.000044\n"
     ]
    }
   ],
   "source": [
    "# super parameters init\n",
    "lr = 0.03\n",
    "num_epochs = 5\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum()  \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  \n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9997],\n",
       "         [-3.4001]], requires_grad=True),\n",
       " [2, -3.4],\n",
       " tensor([4.2005], requires_grad=True),\n",
       " 4.2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, true_w, b, true_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型使用pytorch的简洁实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据集\n",
    "在这里生成数据集跟从零开始的实现中是完全一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "\n",
    "# put dataset into DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,            # torch TensorDataset format\n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # whether shuffle the data or not\n",
    "    num_workers=2,              # read data in multithreading\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0764, -0.7914],\n",
      "        [ 0.7019,  0.4842],\n",
      "        [-0.9500,  0.0962],\n",
      "        [-1.9630, -0.0114],\n",
      "        [ 1.5001, -1.8069],\n",
      "        [ 0.5231, -0.8997],\n",
      "        [ 0.4790, -1.2343],\n",
      "        [ 0.2210, -0.1916],\n",
      "        [-1.6050, -0.3383],\n",
      "        [ 1.1611, -1.1007]]) \n",
      " tensor([ 7.0467,  3.9535,  1.9725,  0.3098, 13.3670,  8.3039,  9.3547,  5.2812,\n",
      "         2.1356, 10.2552])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()      # call father function to init \n",
    "        self.linear = nn.Linear(n_feature, 1)  # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "net = LinearNet(num_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# ways to init a multilayer network\n",
    "# method one\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, 1)\n",
    "    # other layers can be added here\n",
    "    )\n",
    "\n",
    "# method two\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(num_inputs, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# method three\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(num_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0142, -0.0161]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()    # nn built-in squared loss function\n",
    "                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000224\n",
      "epoch 2, loss: 0.000060\n",
      "epoch 3, loss: 0.000085\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两种实现方式的比较\n",
    "1. 从零开始的实现（推荐用来学习）\n",
    "\n",
    "   能够更好的理解模型和神经网络底层的原理\n",
    "   \n",
    "\n",
    "2. 使用pytorch的简洁实现\n",
    "\n",
    "   能够更加快速地完成模型的设计与实现\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
